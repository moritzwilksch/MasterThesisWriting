\section{Theoretical Background}



% =======================================================================
\subsection{Sentiment Analysis}  % TODO: wording
text here?
% -----------------------------------------------------------------------
\subsubsection{Operationalization of Sentiment}
% todo: vvv weak line of argument
Before surveying the literature on automated sentiment analysis models, the term ``Sentiment'' and its operationalization in the scientific literature need to be clearly defined. \shortciteA{munezero2014they} note that the terms \emph{emotion}, \emph{sentiment}, and \emph{opinion} are often used interchangeably, especially in the literature on NLP. However, there are important distinctions to be made between these terms. Emotions can be seen as moods that are not very long-lasting and are caused ``when we perceive positive or negative significant changes in our personal situation'' \shortcite[p.~3]{ben2001subtlety}. On the other hand, a sentiment is defined as ``an acquired and relatively permanent major neuropsychic disposition'' \cite[p.~16]{cattell1940sentiment}. This renders sentiments different from opinions, which are ``personal interpretations of information formed in the mind'' \cite[p.~4]{munezero2014they} and thus require a specific piece of information to interpret. %todo: wording
Despite the differences in the definition of these terms, they are used in ambiguous ways in the field of NLP. In particular, sentiment analysis and opinion mining refer to the same area of research \cite{liu2012book} and are more prevalent than studies on emotion extraction \shortcite{ravi2015survey}, potentially because emotions are a more complex construct and cannot be fully conveyed through text \shortcite{munezero2014they}.

Another challenge is the operationalization of emotions, sentiments, or opinions. For example, emotion extraction studies like the ones conducted by \shortciteA{li2014text} or \shortciteA{aman2007identifying} tend to frame the problem as a six-class classification task where each class corresponds to one of the six basic emotions proposed by \shortciteA{ekman1971constants}. These six emotions are happiness, sadness, anger, surprise, disgust, and fear. However, \shortciteA{aman2007identifying} point out that the inter-rater reliability for this classification task on a corpus of text can be as low as 60\%, indicating that emotion extraction is a non-trivial task even for human annotators. There are variations of this measurement scale, like the ``Profile of Mood States'' questionnaire \shortcite{mcnair1971manual} which measures a different set of six emotional states. What all of them have in common is that they utilize a multi-dimensional scale to assess emotional states. \newline
On the other hand, the literature on the measurements of sentiment and opinion often employs simpler, even one-dimensional scales. The most prominent way of operationalizing sentiment is sentiment \emph{polarity}, which categorizes each unit of analysis as positive, negative, or, in some cases, neutral \cite{ravi2015survey}.

Finance-specific, alternative operationalization of sentiment:
\begin{itemize}[noitemsep]
	\item VIX
	\item Fear \& greed index, more in Aggarwal (2018)
\end{itemize}


\begin{itemize}[noitemsep]
	\item Definition: ``Opinion'' would be a more accurate term (Munezero, 2014)
	\item Scales: continuous $\in [-1, 1]$, discrete $\in \{pos, neg, neu\}$, 1-5 star reviews \dots
	\item In this work: focus on SA and opinion mining (i.e. everything on uni-dimensional scales!)
\end{itemize}


\newpage %todo: remove




\subsubsection{Applications of Sentiment Analysis}

\begin{itemize}
	\item Social sentiment @IBKR?
\end{itemize}


\begin{itemize}[noitemsep]
	\item market research
	\item return \& vola forecasting
	\item Other applications see Ravi \& Ravi and Liu Book
\end{itemize}

% =======================================================================
\subsection{Automated Sentiment Analysis}


% -----------------------------------------------------------------------
\subsubsection{Data Sets for Sentiment Analysis}
Mention data-centric AI!
\begin{itemize}[noitemsep]
	\item describe different task types
	\begin{itemize}
		\item different scales
		\item different UoA: Sentence, Document, Aspect-based
	\end{itemize}
	\item describe different domains + challenges (financial posts on social media)
	\begin{itemize}[noitemsep]
		\item Platforms: Twitter, StockTwits, Reddit, Crypto-specific stuff
		\item Data characteristica: Reddit posts vs. Twitter posts (compare avg. length of each?)
\end{itemize}
	\item Use SemEval later on!
	\item We develop a data set that is a) finance-specific and b) sampled from a social media context. this is new. so far: financial, but not SM (FinancialPhrasebank) or vice versa (SemEval2017)
\end{itemize}

% -----------------------------------------------------------------------
\subsubsection{Dictionary-based Models}


% -----------------------------------------------------------------------
\subsubsection{Machine-Learning-based Models}
\begin{itemize}[noitemsep]
	\item Note: there aren't really any non-DL ML models out there
	\item Recurrent models
	\item Transformer models
	\item LLMs
\end{itemize}


\emph{Argument:} We can only consider models that are available as artifacts. Theoretical papers cannot be considered, as we can't reproduce their models/apply them in our experiments










% =======================================================================
\subsection{Research Gap}
\begin{itemize}[noitemsep]
	\item performance benchmarks of LLMs (and all other models too, right?) on domain-specific texts
	\item development of a data set: There is also no data set on SM financial data 	
\end{itemize}

\input{assets/tables/static/research_gap_matrix.tex}





% =======================================================================
\subsection{Conceptual Framework}

\input{assets/tikz_figures/conceptual_framework.tex}

\emph{Research Questions}: Do LLMs perform well on domain-specific sentiment ananylsis tasks? How do they compare to smaller, machine-learning-based models as well as generic off-the-shelf models? Can simple, domain-specific models outperform LLMs/fine-tuned LLMs? Even if not, how do their memory/compute/cost footprints compare? 

Models to build:

\input{assets/tables/static/models_to_build.tex}








