\section{Theoretical Background}



% =======================================================================
\subsection{Sentiment Analysis}  % TODO: wording

% -----------------------------------------------------------------------
\subsubsection{Operationalization of Sentiment}
\begin{itemize}[noitemsep]
	\item Definition: ``Opinion'' would be a more accurate term (Munezero, 2014)
	\item Scales: continuous $\in [-1, 1]$, discrete $\in \{pos, neg, neu\}$, 1-5 star reviews \dots
\end{itemize}

% -----------------------------------------------------------------------
\subsubsection{Sentiment in the Financial Context}

Finance-specific, alternative operationalization of sentiment:
\begin{itemize}[noitemsep]
	\item VIX
	\item Fear \& greed index, more in Aggarwal (2018)
	\item Social sentiment @IBKR?
\end{itemize}

% =======================================================================
\subsection{Automated Sentiment Analysis}


% -----------------------------------------------------------------------
\subsubsection{Data Sets for Sentiment Analysis}
Mention data-centric AI!
\begin{itemize}[noitemsep]
	\item describe different task types
	\item describe different domains + challenges (financial posts on social media)
	\begin{itemize}[noitemsep]
		\item Platforms: Twitter, StockTwits, Reddit, Crypto-specific stuff
		\item Data characteristica: Reddit posts vs. Twitter posts (compare avg. length of each?)
\end{itemize}
	\item Use SemEval later on!
	\item We develop a data set that is a) finance-specific and b) sampled from a social media context. this is new. so far: financial, but not SM (FinancialPhrasebank) or vice versa (SemEval2017)
\end{itemize}

% -----------------------------------------------------------------------
\subsubsection{Dictionary-based Models}


% -----------------------------------------------------------------------
\subsubsection{Machine-Learning-based Models}
\begin{itemize}[noitemsep]
	\item Note: there aren't really any non-DL ML models out there
	\item Recurrent models
	\item Transformer models
	\item LLMs
\end{itemize}


\emph{Argument:} We can only consider models that are available as artifacts. Theoretical papers cannot be considered, as we can't reproduce their models/apply them in our experiments










% =======================================================================
\subsection{Research Gap}
\begin{itemize}[noitemsep]
	\item performance benchmarks of LLMs (and all other models too, right?) on domain-specific texts
	\item development of a data set: There is also no data set on SM financial data 	
\end{itemize}

\input{assets/tables/static/research_gap_matrix.tex}





% =======================================================================
\subsection{Conceptual Framework}

\input{assets/tikz_figures/conceptual_framework.tex}

\emph{Research Questions}: Do LLMs perform well on domain-specific sentiment ananylsis tasks? How do they compare to smaller, machine-learning-based models as well as generic off-the-shelf models? Can simple, domain-specific models outperform LLMs/fine-tuned LLMs? Even if not, how do their memory/compute/cost footprints compare? 

Models to build:

\input{assets/tables/static/models_to_build.tex}








