\section{Theoretical Background}



% =======================================================================
\subsection{Sentiment Analysis}  % TODO: wording
%todo: text here?
% -----------------------------------------------------------------------
\subsubsection{Operationalization of Sentiment}
% todo: vvv weak line of argument
Before surveying the literature on automated sentiment analysis models, the term ``Sentiment'' and its operationalization in the scientific literature need to be clearly defined. \shortciteA{munezero2014they} note that the terms \emph{emotion}, \emph{sentiment}, and \emph{opinion} are often used interchangeably, especially in the literature on NLP. However, there are important distinctions to be made between these terms. Emotions can be seen as moods that are not very long-lasting and are caused ``when we perceive positive or negative significant changes in our personal situation'' \shortcite[p.~3]{ben2001subtlety}. On the other hand, a sentiment is defined as ``an acquired and relatively permanent major neuropsychic disposition'' \cite[p.~16]{cattell1940sentiment}. This renders sentiments different from opinions, which are ``personal interpretations of information formed in the mind'' \cite[p.~4]{munezero2014they} and thus require a specific piece of information to interpret. %todo: wording
Despite the differences in the definition of these terms, they are used in ambiguous ways in the field of NLP. In particular, sentiment analysis and opinion mining refer to the same area of research \cite{liu2012book} and are more prevalent than studies on emotion extraction \shortcite{ravi2015survey}, potentially because emotions are a more complex construct and cannot be fully conveyed through text \shortcite{munezero2014they}.

Another challenge is the operationalization of emotions, sentiments, or opinions. For example, emotion extraction studies like the ones conducted by \shortciteA{li2014text} or \shortciteA{aman2007identifying} tend to frame the problem as a six-class classification task where each class corresponds to one of the six basic emotions proposed by \shortciteA{ekman1971constants}. These six emotions are happiness, sadness, anger, surprise, disgust, and fear. However, \shortciteA{aman2007identifying} point out that the inter-rater reliability for this classification task on a corpus of text can be as low as 60\%, indicating that emotion extraction is a non-trivial task even for human annotators. There are variations of this measurement scale, like the ``Profile of Mood States'' questionnaire \shortcite{mcnair1971manual} which measures a different set of six emotional states. What all of these scales have in common is that they are multi-dimensional measurements to assess emotional states. \newline
On the other hand, the literature on sentiment analysis and opinion mining often employs simpler, even one-dimensional scales. The most prominent way of operationalizing sentiment is sentiment \emph{polarity}, which categorizes each unit of analysis as positive, negative, or, in some cases, neutral \cite{ravi2015survey}. Other approaches try to evaluate the sentiment in a piece of text as a real number between -1 and 1, a one to five-star rating (e.g. movie or product reviews), or another numeric score outside of any pre-determined interval.\newline
Besides the type of the employed sentiment measurement, the literature can also be categorized according to the unit of analysis it is concerned with. \shortciteA{liu2012book} distinguishes the units of analysis as being either document-level, sentence-level, or entity- and aspect-based. Document-level SA operates separately on every document in a corpus, e.g. each review for a product or movie or each social media post in a collection. This granularity is used most often as it aligns with the nature of a document as a self-contained piece of text by one author. For longer documents, sentence-level SA enables researchers to score sentiment on a per-sentence basis and subsequently calculate aggregate scores for the document. However, this comes at the expense of ignoring the inter-sentence context. Finally, aspect-based SA does not only generate sentiment scores but links these scores to the aspects they are referring to. This is mostly used in the analysis of product reviews, where some aspects of a product are rated positively while others are not, e.g. a computer with great battery life but low compute performance \shortcite{pontiki2016semeval}.  \textcolor{red}{ref this later: reddit is too long for doc-level}

In addition to these definitions which are applicable in the field of NLP, other domains have their own definitions of sentiment. For the domain of finance, \citeA{aggarwal2019defining} provides an overview of all sentiment measures that have been historically used. In recent literature, two of them stick out as the most common: the Chicago Board Options Exchange Volatility Index (VIX) and the Put/Call Ratio (PCR). The calculation of the VIX is based on options on the Standard and Poor's 500 index (S\&P500) and represents the \emph{expected} level of volatility in the next month \shortcite{cboeVIX}. Its forward-looking nature makes it different from usual sentiment measurements which are based on historical data. Given that volatility is defined as the standard deviation of returns, it is not directly comparable to sentiment classes like ``positive'' or ``negative'' although lower volatility is generally associated with higher returns \shortcite{zare2013monetary}. The mathematically simpler Put/Call Ratio is the ratio between the volume of traded put options and call options. A PCR above 1 implies that put options are being traded more than call options indicating a negative market sentiment. Apart from these easily quantifiable versions of market sentiment in finance, the field starts recognizing that retail investor's emotions, sentiments and opinions carry valuable information. The advent of behavioral finance describes and accounts for human biases in decision making processes, some of which can be assessed using sentiment analysis \shortcite{hirshleifer2015behavioral}.

In this work, \dots 

\begin{itemize}[noitemsep]
	\item In this work: focus on SA and opinion mining (i.e. everything on uni-dimensional scales!) as defined in the field of NLP. This ``Social Sentiment'' definition is also slowly getting traction in finance, btw. Also here in this work: document-level!
\end{itemize}


\newpage %todo: remove




\subsubsection{Applications of Sentiment Analysis}

\begin{itemize}
	\item Social sentiment @IBKR?
\end{itemize}


\begin{itemize}[noitemsep]
	\item market research: opinion mining can replace surveys and focus groups and is cheaper with information abundantly available on microblogs
	\item Sentiment extracted from posts on the microblogging platform Twitter has been shown to correlate with public opinion to a point where it can be used to forecast election results \shortcite{o2010tweets, tumasjan2010predicting}.
	\item return \& vola forecasting (see old report)
	\item Other applications see Ravi \& Ravi and Liu Book (pdf page 19)
\end{itemize}

% =======================================================================
\subsection{Automated Sentiment Analysis}


% -----------------------------------------------------------------------
\subsubsection{Data Sets for Sentiment Analysis}
Mention data-centric AI!
\begin{itemize}[noitemsep]
	\item describe different task types
	\begin{itemize}
		\item different scales
		\item different UoA: Sentence, Document, Aspect-based
	\end{itemize}
	\item describe different domains + challenges (financial posts on social media)
	\begin{itemize}[noitemsep]
		\item Platforms: Twitter, StockTwits, Reddit, Crypto-specific stuff
		\item Data characteristica: Reddit posts vs. Twitter posts (compare avg. length of each?)
\end{itemize}
	\item Use SemEval later on!
	\item We develop a data set that is a) finance-specific and b) sampled from a social media context. this is new. so far: financial, but not SM (FinancialPhrasebank) or vice versa (SemEval2017)
\end{itemize}

% -----------------------------------------------------------------------
\subsubsection{Dictionary-based Models}
\begin{itemize}
	\item see VADER paper: either words are pos/neg (LIWC, GI, HuLiu) OR scored with valence (ANEW, SentiWordNet)
	\item finish with benchmark paper from last year: VADER > everything
\end{itemize}

% -----------------------------------------------------------------------
\subsubsection{Machine-Learning-based Models}
\begin{itemize}[noitemsep]
	\item Note: there aren't really any non-DL ML models out there
	\item Recurrent models
	\item Transformer models
	\item LLMs
\end{itemize}


\emph{Argument:} We can only consider models that are available as artifacts. Theoretical papers cannot be considered, as we can't reproduce their models/apply them in our experiments










% =======================================================================
\subsection{Research Gap}
\begin{itemize}[noitemsep]
	\item performance benchmarks of LLMs (and all other models too, right?) on domain-specific texts
	\item development of a data set: There is also no data set on SM financial data 	
\end{itemize}

\input{assets/tables/static/research_gap_matrix.tex}





% =======================================================================
\subsection{Conceptual Framework}

\input{assets/tikz_figures/conceptual_framework.tex}

\emph{Research Questions}: Do LLMs perform well on domain-specific sentiment ananylsis tasks? How do they compare to smaller, machine-learning-based models as well as generic off-the-shelf models? Can simple, domain-specific models outperform LLMs/fine-tuned LLMs? Even if not, how do their memory/compute/cost footprints compare? 

Models to build:

\input{assets/tables/static/models_to_build.tex}








