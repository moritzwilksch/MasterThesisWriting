\section{Introduction}

The advent of social networking sites (SNS) presents the unique opportunity to tap into an enormous stream of data that users share with the world. However, most of this data comes in the form of images, videos, or text and thus is challenging to analyze. Therefore, researchers utilize automated tools to extract information from these types of media. For images, they can apply object detection to infer what kind of objects are present in a photograph. Speech detection can transcribe spoken words in videos, and named entity recognition can be utilized to recognize entities mentioned in a text. Among these technologies, sentiment analysis has been widely used by scholars and practitioners to derive actionable insights across domains. Also known as ``opinion mining'', sentiment analysis is the practice of automatically extracting sentiments or opinions from short pieces of text. It has successfully been used to detect sentiment towards political parties \shortcite{luo2022entity} or consumer products \cite{pontiki2016semeval} from posts on SNS. The extracted sentiment data can then be used for downstream analyses. For example, for the domain of finance, research has shown that sentiment obtained from SNS can help forecast stock market volatility \shortcite{antweiler2004all, audrino2020impact}, trading volume \shortcite{oliveira2017impact}, and even future returns \shortcite{ren2018forecasting, wilksch2022predictive}. However, a problem with the most frequently used sentiment analysis models is that they were designed for working with generic texts. They exploit signaling words like ``good'' or ``bad'' for determining the sentiment of a text. While it has been shown that these models perform excellently on generic social media posts \cite{al2020evaluating}, their performance on domain-specific texts is questionable. Nevertheless, they are still applied blindly and their output is considered ``ground truth'' for research applications studying large quantities of data. While there are studies that design alternative models usable for specific domains, few of them publish their models as usable artifacts to enable other researchers to benefit from more accurate sentiment assessments.

This work analyzes and proposes a solution to this issue for the domain of financial market sentiment analysis using a Design Science Research approach. With the goal of building a usable model artifact that can automatically identify an author's opinion about the future of a stock's price, we collect and manually label data to compile a gold-standard dataset of finance-related tweets. We use this data to benchmark existing sentiment models trained on either generic social media data or finance-related texts. After establishing this performance benchmark of models that are popular in the literature, we design and train multiple contending sentiment models. We publish one of the proposed models as an easy-to-use python library such that it can be used for obtaining sentiment scores for future studies.

The remainder of this work is structured as follows. The \emph{Theoretical Background} section introduces the concepts needed for automating sentiment analysis using statistical models. It lays out how sentiment is operationalized in the literature, explains the technologies used for automating sentiment analysis, and surveys the literature on existing approaches. Finally, it highlights the research problem we aim to solve by introducing the research questions and the research paradigm we follow to answer them. The \emph{Methodology} section gives a detailed explanation on how the data used for all experiments were collected, labelled, and preprocessed. Furthermore, it lays out the experimental setup we use to train all models. Subsequently, we present dataset statistics, an evaluation of model performance and detailed model diagnostics in the \emph{Results} section. We highlight the issue of handling texts with no clear sentiment, provide an example use-case of how the proposed model might be used for further research and introduce the python library that contains the final research artifact. We will discuss the emerging findings in the \emph{Discussion} and provide a final, high-level summary of the work and its findings in the \emph{Conclusion}.